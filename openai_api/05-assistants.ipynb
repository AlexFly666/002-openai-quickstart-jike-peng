{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexFly666/002-openai-quickstart-jike-peng/blob/main/openai_api/05-assistants.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c87bc55-5547-4079-a6d8-41e8198d2356",
      "metadata": {
        "id": "4c87bc55-5547-4079-a6d8-41e8198d2356"
      },
      "source": [
        "# 快速入门 Assistants API\n",
        "\n",
        "Assistants API 允许您在自己的应用程序中构建人工智能助手。一个助手有其指令，并可以利用模型、工具和知识来回应用户查询。\n",
        "\n",
        "Assistants API 目前支持三种类型的工具：\n",
        "- 代码解释器 Code Interpreter\n",
        "- 检索 Retrieval\n",
        "- 函数调用 Function calling\n",
        "\n",
        "使用 [Playground](https://platform.openai.com/playground?mode=assistant) 可以在线探索和测试 Assistants API 功能。\n",
        "\n",
        "本入门指南将指导您完成创建和运行使用代码解释器的助手的关键步骤，以下是使用 Assistants API 标准流程：\n",
        "1. 通过定义其自定义指令并选择 LLM 来创建一个助手(Assistant)。如果有需求，可以添加文件并启用诸如代码解释器、检索和函数调用等工具。\n",
        "2. 当用户开始对话时，创建一个线程(Thread)。\n",
        "3. 当用户提问时，向线程添加消息(Messages)。\n",
        "4. 通过调用模型和工具在线程上运行助手以生成响应。\n",
        "\n",
        "![assistans](https://github.com/AlexFly666/002-openai-quickstart-jike-peng/blob/main/openai_api/images/diagram-assistant.png?raw=1)\n",
        "\n",
        "OBJECT | WHAT IT REPRESENTS\n",
        "--- | ---\n",
        "Assistant | 专为特定目的构建的人工智能，使用 OpenAI 的模型并调用工具\n",
        "Thread | 助手与用户之间的对话会话。线程存储消息，并自动处理截断，以将内容适应模型的上下文。\n",
        "Message | 由助手或用户创建的消息。消息可以包括文本、图片和其他文件。消息以列表形式存储在线程上。\n",
        "Run | 在线程上对一个助手的调用。助手利用其配置和线程的消息执行任务，通过调用模型和工具。作为运行的一部分，助手会将消息追加到线程中。\n",
        "Run Step | 助手在运行中采取的详细步骤列表。助手可以在其运行期间调用工具或创建消息。检查运行步骤可以让您深入了解助手如何得出最终结果。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a8bbea-2f1f-45a4-b3e8-929614c66790",
      "metadata": {
        "id": "b7a8bbea-2f1f-45a4-b3e8-929614c66790"
      },
      "source": [
        "\n",
        "## 使用 Assistants 开发数学辅导老师\n",
        "\n",
        "在这个示例中，我们正在创建一个数学辅导助手，并启用了代码解释器工具。\n",
        "\n",
        "### 第一步：创建助手\n",
        "参考：https://platform.openai.com/docs/api-reference/assistants/createAssistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d2227bb3-179a-43c2-b389-60ecbd0dfce5",
      "metadata": {
        "id": "d2227bb3-179a-43c2-b389-60ecbd0dfce5",
        "outputId": "16278d0e-1899-46b5-f24c-e10c966397fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==1.57.4 in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai==1.57.4) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.57.4) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.57.4) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.57.4) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.57.4) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.57.4) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.57.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.57.4) (2.27.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install openai==1.57.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://vip.apiyi.com/v1/assistants\" \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
        "  -H \"OpenAI-Beta: assistants=v2\" \\\n",
        "  -d '{ \\\n",
        "    \"instructions\": \"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\", \\\n",
        "    \"name\": \"Math Tutor\", \\\n",
        "    \"tools\": [{\"type\": \"code_interpreter\"}], \\\n",
        "    \"model\": \"gpt-4o\" \\\n",
        "  }'"
      ],
      "metadata": {
        "id": "HdT0wD8JwdsB"
      },
      "id": "HdT0wD8JwdsB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "052b55e0-8170-41de-a721-0961606c793e",
      "metadata": {
        "id": "052b55e0-8170-41de-a721-0961606c793e",
        "outputId": "580097ed-84f1-448f-bd0a-9725cbf47604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalServerError",
          "evalue": "Error code: 501 - {'error': {'message': 'API not implemented', 'localized_message': '', 'type': 'shell_api_error', 'param': '', 'code': 'api_not_implemented'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7c7b2fb4e248>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 创建一个名为 \"Math Tutor\" 的助手，它是一个个人数学辅导老师。这个助手能够编写并运行代码来解答数学问题。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m assistant = client.beta.assistants.create(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Math Tutor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minstructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"You are a personal math tutor. Write and run code to answer math questions.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/beta/assistants.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, description, instructions, metadata, name, response_format, temperature, tool_resources, tools, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \"\"\"\n\u001b[1;32m    145\u001b[0m         \u001b[0mextra_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"OpenAI-Beta\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"assistants=v2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_headers\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;34m\"/assistants\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         )\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1096\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1096\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mInternalServerError\u001b[0m: Error code: 501 - {'error': {'message': 'API not implemented', 'localized_message': '', 'type': 'shell_api_error', 'param': '', 'code': 'api_not_implemented'}}"
          ]
        }
      ],
      "source": [
        "import openai  # 导入 openai 库\n",
        "\n",
        "# 从环境变量 OPENAI_API_KEY 中获取 API 密钥\n",
        "# client = openai.OpenAI()\n",
        "# OpenAI Python SDK v1.0 更新后的使用方式\n",
        "# 使用代理方式，需要修改base_url\n",
        "client = openai.OpenAI(\n",
        "    api_key=\"XXX\", # 你的KEY\n",
        "    base_url=\"https://vip.apiyi.com/v1\"\n",
        ")\n",
        "# 创建一个名为 \"Math Tutor\" 的助手，它是一个个人数学辅导老师。这个助手能够编写并运行代码来解答数学问题。\n",
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}],  # 使用工具：代码解释器\n",
        "    model=\"gpt-3.5-turbo-1106\",  # 使用模型： GPT-4o\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 异常InternalServerError: Error code: 501 - {'error': {'message': 'API not implemented', 'localized_message': '', 'type': 'shell_api_error', 'param': '', 'code': 'api_not_implemented'}}\n",
        "# https://vip.apiyi.com/v1不支持assistants，因为它集成了文件能力，于是不支持\n",
        "\n",
        "# 常见问题：API中转站支持微调吗？\n",
        "\n",
        "# 答：由于调用逻辑关系，微调只能创建，但因为中转用了很多个Key（背后是号池：很多个的api账号），\n",
        "# 但是非本号的 key 调用不通的\n",
        "\n",
        "# 也就是中转站不支持 fine tune 微调，另外不支持 files文件 接口。 但支持 补全/对话，和 函数调用 functions\n",
        "\n",
        "# 也就是微调 API 只能买官网API充值的直连API"
      ],
      "metadata": {
        "id": "_oOtF96jwmGQ"
      },
      "id": "_oOtF96jwmGQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1106c286-aa3b-4076-9992-37b1a56743c6",
      "metadata": {
        "id": "1106c286-aa3b-4076-9992-37b1a56743c6"
      },
      "source": [
        "### 第二步：创建线程\n",
        "\n",
        "一个线程代表用户和一个或多个助手之间的对话。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c7e57e-8e95-4411-ae53-0ae3ac004c62",
      "metadata": {
        "id": "d1c7e57e-8e95-4411-ae53-0ae3ac004c62"
      },
      "outputs": [],
      "source": [
        "# 创建一个交流线程\n",
        "thread = client.beta.threads.create()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b958896-d802-445e-8098-0a443399cf43",
      "metadata": {
        "id": "5b958896-d802-445e-8098-0a443399cf43"
      },
      "source": [
        "### 第三步：往线程添加消息\n",
        "\n",
        "用户或APP创建的消息内容将作为消息对象（Message Object）添加到线程中。\n",
        "\n",
        "消息可以包含文本和文件，向线程添加的消息数量没有限制 - OpenAI 会智能地截断任何不适合模型上下文窗口的内容。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f372ca8f-53be-4c3c-9e0a-c1b41b8955e7",
      "metadata": {
        "id": "f372ca8f-53be-4c3c-9e0a-c1b41b8955e7"
      },
      "outputs": [],
      "source": [
        "# 在该线程中创建一条用户消息，并提交一个数学问题：“我需要解方程 `3x + 11 = 14`。你能帮忙吗？”\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c525954-63ef-44b1-94de-75a5b43568da",
      "metadata": {
        "id": "4c525954-63ef-44b1-94de-75a5b43568da"
      },
      "source": [
        "### 第四步：调用助手\n",
        "\n",
        "一旦所有用户消息都添加到了线程中，你可以使用任何助手运行该线程。\n",
        "\n",
        "创建一个运行会使用与助手相关的模型和工具来生成响应。这些响应将作为助手消息添加到线程中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a77c01e-7a68-41da-909b-d8e675a50d26",
      "metadata": {
        "id": "7a77c01e-7a68-41da-909b-d8e675a50d26"
      },
      "outputs": [],
      "source": [
        "# 创建并等待执行流完成，用于处理该线程中的交互和问题解答\n",
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\",  # 以 Jane Doe 称呼用户，并且用户拥有高级账户\n",
        ")\n",
        "\n",
        "print(\"Run completed with status: \" + run.status)  # 打印执行流的完成状态\n",
        "\n",
        "# 如果执行流状态为 \"completed\"（已完成），则获取并打印所有消息\n",
        "if run.status == \"completed\":\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "\n",
        "    print(\"\\nMessages:\\n\")\n",
        "    for message in messages:\n",
        "        assert message.content[0].type == \"text\"\n",
        "        print(f\"Role: {message.role.capitalize()}\")  # 角色名称首字母大写\n",
        "        print(\"Message:\")\n",
        "        print(message.content[0].text.value + \"\\n\")  # 每条消息后添加空行以增加可读性"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea5e1bca-3401-4db8-b3ae-b2797d11680b",
      "metadata": {
        "id": "ea5e1bca-3401-4db8-b3ae-b2797d11680b"
      },
      "source": [
        "### 通过 Assistant ID 删除指定助手"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7535ee48-2107-465d-b5fa-b12356ba8b87",
      "metadata": {
        "id": "7535ee48-2107-465d-b5fa-b12356ba8b87"
      },
      "outputs": [],
      "source": [
        "# 删除创建的助手\n",
        "client.beta.assistants.delete(assistant.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "025b777a-d279-4c62-8a50-7d24a1baaa5a",
      "metadata": {
        "id": "025b777a-d279-4c62-8a50-7d24a1baaa5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "929b787f-372b-4c35-9769-381d41c91042",
      "metadata": {
        "id": "929b787f-372b-4c35-9769-381d41c91042"
      },
      "source": [
        "### 使用流式输出实现数学辅导老师"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b68ff9fa-e815-444b-b9e3-9dc062a0cc00",
      "metadata": {
        "id": "b68ff9fa-e815-444b-b9e3-9dc062a0cc00"
      },
      "outputs": [],
      "source": [
        "# 官方案例\n",
        "from typing_extensions import override\n",
        "from openai import AssistantEventHandler\n",
        "import openai\n",
        "\n",
        "# 从环境变量 OPENAI_API_KEY 中获取 API 密钥\n",
        "client = openai.OpenAI()\n",
        "\n",
        "# 创建一个名为 \"Math Tutor\" 的助手，它是一个个人数学辅导老师。这个助手能够编写并运行代码来解答数学问题。\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Math Tutor\",\n",
        "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}],  # 工具包括代码解释器\n",
        "    model=\"gpt-4-1106-preview\",  # 使用的模型是 GPT-4\n",
        ")\n",
        "\n",
        "# 创建一个交流线程\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# 在该线程中创建一条消息，表示用户角色，并提交一个数学问题：“我需要解方程 `3x + 11 = 14`。你能帮忙吗？”\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
        ")\n",
        "\n",
        "print(\"starting run stream\")  # 打印开始执行流的消息\n",
        "\n",
        "# First, we create a EventHandler class to define\n",
        "# how we want to handle the events in the response stream.\n",
        "\n",
        "class EventHandler(AssistantEventHandler):\n",
        "  @override\n",
        "  def on_text_created(self, text) -> None:\n",
        "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
        "\n",
        "  @override\n",
        "  def on_text_delta(self, delta, snapshot):\n",
        "    print(delta.value, end=\"\", flush=True)\n",
        "\n",
        "  def on_tool_call_created(self, tool_call):\n",
        "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "  def on_tool_call_delta(self, delta, snapshot):\n",
        "    if delta.type == 'code_interpreter':\n",
        "      if delta.code_interpreter.input:\n",
        "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
        "      if delta.code_interpreter.outputs:\n",
        "        print(f\"\\n\\noutput >\", flush=True)\n",
        "        for output in delta.code_interpreter.outputs:\n",
        "          if output.type == \"logs\":\n",
        "            print(f\"\\n{output.logs}\", flush=True)\n",
        "\n",
        "# Then, we use the `stream` SDK helper\n",
        "# with the `EventHandler` class to create the Run\n",
        "# and stream the response.\n",
        "\n",
        "with client.beta.threads.runs.stream(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        "  instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
        "  event_handler=EventHandler(),\n",
        ") as stream:\n",
        "  stream.until_done()\n",
        "\n",
        "\n",
        "# 删除创建的助手\n",
        "client.beta.assistants.delete(assistant.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff800570-5539-43a2-8c36-f6e7958c112a",
      "metadata": {
        "id": "ff800570-5539-43a2-8c36-f6e7958c112a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "070e5f61-1931-46b6-a025-72da8116a125",
      "metadata": {
        "id": "070e5f61-1931-46b6-a025-72da8116a125"
      },
      "source": [
        "## 开发 Python 代码小助手"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0604c6b-5227-454a-a036-3cbe8f071d7e",
      "metadata": {
        "id": "e0604c6b-5227-454a-a036-3cbe8f071d7e"
      },
      "outputs": [],
      "source": [
        "import openai  # 导入 openai 库\n",
        "import time\n",
        "\n",
        "# 从环境变量 OPENAI_API_KEY 中获取 API 密钥\n",
        "client = openai.OpenAI()\n",
        "\n",
        "# 创建一个名为 \"Python Master\" 的助手，它能根据需求生成可以运行的 Python 代码\n",
        "assistant_python = client.beta.assistants.create(\n",
        "    name=\"Python Master\",\n",
        "    instructions=\"You are a Python Expert. Generate runnable Python code according to messages.\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}],  # 使用工具：代码解释器\n",
        "    model=\"gpt-4o\",  # 使用模型： GPT-4\n",
        ")\n",
        "\n",
        "# 创建一个交流线程\n",
        "thread_python = client.beta.threads.create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca4de29a-c87f-4f4a-9034-9aed4a82f641",
      "metadata": {
        "id": "ca4de29a-c87f-4f4a-9034-9aed4a82f641"
      },
      "outputs": [],
      "source": [
        "assistant_python.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ad0533f-519f-40a0-97ed-73b235f2c18a",
      "metadata": {
        "id": "0ad0533f-519f-40a0-97ed-73b235f2c18a"
      },
      "outputs": [],
      "source": [
        "thread_python.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610371e1-82bf-47e5-bbb4-63f3bec8e7f7",
      "metadata": {
        "id": "610371e1-82bf-47e5-bbb4-63f3bec8e7f7"
      },
      "outputs": [],
      "source": [
        "# 在该线程中创建一条信息\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread_python.id,\n",
        "    role=\"user\",\n",
        "    content=\"快速排序咋个写？\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "076da137-0c5e-4836-bb3e-663c81a2790e",
      "metadata": {
        "id": "076da137-0c5e-4836-bb3e-663c81a2790e"
      },
      "outputs": [],
      "source": [
        "message.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae385730-7d50-45ca-af53-748cf641a1a7",
      "metadata": {
        "id": "ae385730-7d50-45ca-af53-748cf641a1a7"
      },
      "outputs": [],
      "source": [
        "# 创建并等待执行流完成，用于处理该线程中的交互和问题解答\n",
        "# 方式一：create_and_poll创建并轮询方式\n",
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread_python.id,\n",
        "    assistant_id=assistant_python.id,\n",
        ")\n",
        "\n",
        "print(\"Run completed with status: \" + run.status)  # 打印执行流的完成状态"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2bd2fdf-9adb-4bb9-8f34-00e360fbf787",
      "metadata": {
        "id": "a2bd2fdf-9adb-4bb9-8f34-00e360fbf787"
      },
      "outputs": [],
      "source": [
        "run.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c02863-5c7a-4582-969d-9a589a52d1e9",
      "metadata": {
        "id": "63c02863-5c7a-4582-969d-9a589a52d1e9"
      },
      "outputs": [],
      "source": [
        "# 方式二：create 和 retrieve方式，判断run状态为（初始为queued）\n",
        "run2 = client.beta.threads.runs.create(\n",
        "    thread_id=thread_python.id,\n",
        "    assistant_id=assistant_python.id,\n",
        ")\n",
        "\n",
        "print(\"Run初始状态 \" + run2.status)  # 打印执行流的完成状态"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea30fc51-3251-48fe-ba2b-48c121b0f086",
      "metadata": {
        "id": "ea30fc51-3251-48fe-ba2b-48c121b0f086"
      },
      "outputs": [],
      "source": [
        "run2.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8745aff3-5e6c-43b3-9532-0ed47ed3d471",
      "metadata": {
        "id": "8745aff3-5e6c-43b3-9532-0ed47ed3d471"
      },
      "outputs": [],
      "source": [
        "while run2.status == \"queued\" or run.status == \"in_progress\":\n",
        "    run2 = client.beta.threads.runs.retrieve(\n",
        "        thread_id=thread_python.id,\n",
        "        run_id=run2.id\n",
        "    )\n",
        "    time.sleep(1)\n",
        "print(\"Run2 completed with status: \" + run2.status)  # 打印执行流的完成状态"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83469189-458d-4130-9e92-a814043ff813",
      "metadata": {
        "id": "83469189-458d-4130-9e92-a814043ff813"
      },
      "outputs": [],
      "source": [
        "# 如果执行流状态为 \"completed\"（已完成），则获取并打印所有消息\n",
        "if run.status == \"completed\":\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread_python.id)\n",
        "\n",
        "    print(\"\\nMessages:\\n\")\n",
        "    for message in messages:\n",
        "        assert message.content[0].type == \"text\"\n",
        "        print(f\"Role: {message.role.capitalize()}\")  # 角色名称首字母大写\n",
        "        print(\"Message:\")\n",
        "        print(message.content[0].text.value + \"\\n\")  # 每条消息后添加空行以增加可读性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2b351d8-8af7-401d-936b-377acfad2b2e",
      "metadata": {
        "id": "f2b351d8-8af7-401d-936b-377acfad2b2e"
      },
      "outputs": [],
      "source": [
        "# 在该线程中创建一条信息\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread_python.id,\n",
        "    role=\"user\",\n",
        "    content=\"红黑树呢？\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a664dc7f-399c-4793-95a0-1bca7b37847c",
      "metadata": {
        "id": "a664dc7f-399c-4793-95a0-1bca7b37847c"
      },
      "outputs": [],
      "source": [
        "# 创建并等待执行流完成，用于处理该线程中的交互和问题解答\n",
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread_python.id,\n",
        "    assistant_id=assistant_python.id,\n",
        ")\n",
        "\n",
        "print(\"Run completed with status: \" + run.status)  # 打印执行流的完成状态"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a76261f-aae9-499e-91d8-0ffc55de8bd3",
      "metadata": {
        "id": "4a76261f-aae9-499e-91d8-0ffc55de8bd3"
      },
      "outputs": [],
      "source": [
        "# 如果执行流状态为 \"completed\"（已完成），则获取并打印所有消息\n",
        "if run.status == \"completed\":\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread_python.id)\n",
        "\n",
        "    print(\"\\nMessages:\\n\")\n",
        "    for message in messages:\n",
        "        assert message.content[0].type == \"text\"\n",
        "        print(f\"Role: {message.role.capitalize()}\")  # 角色名称首字母大写\n",
        "        print(\"Message:\")\n",
        "        print(message.content[0].text.value + \"\\n\")  # 每条消息后添加空行以增加可读性"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76f126e2-64a2-4887-810c-b5059d5bcf56",
      "metadata": {
        "id": "76f126e2-64a2-4887-810c-b5059d5bcf56"
      },
      "outputs": [],
      "source": [
        "# 删除创建的助手\n",
        "client.beta.assistants.delete(assistant_python.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "788179ec-d10e-4cbd-b18b-1cf2b5fa02ee",
      "metadata": {
        "id": "788179ec-d10e-4cbd-b18b-1cf2b5fa02ee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e49e1c65-626f-473c-80c9-2be33bc0a98f",
      "metadata": {
        "id": "e49e1c65-626f-473c-80c9-2be33bc0a98f"
      },
      "source": [
        "## Homework: 将数学辅导老师和Python小助手的代码重构，实现类似 Playground 的对话输入体验"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "541ad829-e6c7-4316-ab2f-03005610fc86",
      "metadata": {
        "id": "541ad829-e6c7-4316-ab2f-03005610fc86"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}