{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexFly666/002-openai-quickstart-jike-peng/blob/main/langchain/langsmith/tracing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5440062-acd7-4ede-b544-904384a4748a",
      "metadata": {
        "id": "a5440062-acd7-4ede-b544-904384a4748a"
      },
      "source": [
        "# LangSmith Tracing 快速入门\n",
        "\n",
        "为了使用追踪（Tracing）功能，必须将`LANGCHAIN_TRACING_V2`环境变量设置为`true`，以便在使用 @traceable或traceable时将跟踪日志记录到LangSmith。使得开发者可以在不更改代码的情况下切换跟踪开关。\n",
        "\n",
        "此外，还需要将 `LANGCHAIN_API_KEY` 环境变量设置好（注册和创建`API_KEY`官方文档链接：https://docs.smith.langchain.com/）\n",
        "\n",
        "### 追踪记录方法\n",
        "\n",
        "本教程将展示多种使用 LangSmith 来记录追踪 LLM 生成内容和性能的方法：\n",
        "- 使用 `@traceable` 装饰器追踪特定 Python 函数\n",
        "- 使用 `wrap_openai` 方法自动追踪 OpenAI 客户端所有调用\n",
        "- 使用 `RunTree` API\n",
        "- 使用 `trace` 上下文管理\n",
        "- 结合 `LangChain` 来追踪记录\n",
        "\n",
        "### 记录到特定项目\n",
        "\n",
        "追踪日志默认会记录在 `default` 项目中，如果想要记录在其他项目，需要在 LangSmith 平台新建项目。然后使用以下方式：\n",
        "- 使用环境变量全量修改：`export LANGCHAIN_PROJECT=my-custom-project`\n",
        "- 动态修改单条记录：`@traceable(project_name=\"my-custom-project\")`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98a0e57-0ba6-4e98-9485-22fdca6bd694",
      "metadata": {
        "id": "b98a0e57-0ba6-4e98-9485-22fdca6bd694"
      },
      "source": [
        "## @traceable 装饰器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5956cb98-b567-4a2f-9ead-1b14742e8bc7",
      "metadata": {
        "id": "5956cb98-b567-4a2f-9ead-1b14742e8bc7"
      },
      "outputs": [],
      "source": [
        "from langsmith import traceable\n",
        "from openai import Client\n",
        "\n",
        "# 创建 OpenAI 客户端\n",
        "# openai = Client()\n",
        "# # OpenAI API调用（代理方式）\n",
        "# openai = Client(\n",
        "#     api_key=\"XXX\",\n",
        "#     base_url=\"https://vip.apiyi.com/v1\"\n",
        "# )\n",
        "\n",
        "# # 智谱API调用\n",
        "# openai = Client(\n",
        "#     api_key=\"XXX\",\n",
        "#     base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
        "# )\n",
        "\n",
        "# DeepSeek API调用\n",
        "openai = Client(\n",
        "    api_key=\"XXX\",\n",
        "    base_url=\"https://api.deepseek.com\"\n",
        ")\n",
        "\n",
        "# 标记函数可追踪\n",
        "@traceable\n",
        "def format_prompt(subject):\n",
        "    # 格式化提示信息\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"你是一个乐于助人的助手。\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"对于一家卖{subject}的店来说，取个什么名字好呢？\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "# 标记函数可追踪，并指定运行类型为 LLM\n",
        "@traceable(run_type=\"llm\")\n",
        "def invoke_llm(messages):\n",
        "    # 调用 OpenAI 的聊天模型\n",
        "    return openai.chat.completions.create(\n",
        "        # OpenAI API\n",
        "        # messages=messages, model=\"gpt-3.5-turbo\", temperature=0\n",
        "        # 智谱API\n",
        "        #messages=messages, model=\"glm-4v-flash\", temperature=0\n",
        "        # DeepSeek API调用\n",
        "        messages=messages, model=\"deepseek-chat\", temperature=0\n",
        "    )\n",
        "\n",
        "# 标记函数可追踪\n",
        "@traceable\n",
        "def parse_output(response):\n",
        "    # 解析并返回模型的输出\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# 标记函数可追踪\n",
        "@traceable\n",
        "def run_pipeline(prompt):\n",
        "    # 运行整个管道流程\n",
        "    messages = format_prompt(prompt)  # 创建提示信息\n",
        "    response = invoke_llm(messages)  # 调用模型\n",
        "    return parse_output(response)  # 解析模型输出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "834711de-9f4a-40e5-90ef-d4fd16c2faff",
      "metadata": {
        "id": "834711de-9f4a-40e5-90ef-d4fd16c2faff",
        "outputId": "b31acfe4-b5b6-4b6a-a11e-f702980f9246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'给一家烤鸭店取名字时，既要突出烤鸭的特色，又要让人印象深刻，同时还要有文化内涵或趣味性。以下是一些建议：\\n\\n### 1. **传统风格**\\n   - **全聚德**（已有知名品牌，但可以参考这种风格）\\n   - **京味轩**：突出北京烤鸭的地域特色。\\n   - **御鸭坊**：带有皇家气息，显得高档。\\n   - **老北京烤鸭**：简单直接，突出传统风味。\\n   - **鸭香阁**：古典雅致，适合传统风格的店铺。\\n\\n### 2. **现代风格**\\n   - **鸭先生**：时尚、亲切，适合年轻消费者。\\n   - **鸭掌门**：霸气且有特色，容易记住。\\n   - **鸭香四溢**：突出烤鸭的香气，吸引顾客。\\n   - **鸭趣**：轻松有趣，适合年轻化的品牌。\\n   - **鸭小厨**：亲切、接地气，适合小型或连锁店。\\n\\n### 3. **创意风格**\\n   - **鸭来了**：简单有趣，容易让人记住。\\n   - **鸭香不怕巷子深**：借用俗语，突出烤鸭的美味。\\n   - **鸭香十里**：夸张地表达烤鸭的香气，吸引顾客。\\n   - **鸭香满堂**：寓意生意兴隆，顾客满堂。\\n   - **鸭香传奇**：带有故事感，吸引顾客的好奇心。\\n\\n### 4. **地域特色**\\n   - **京鸭坊**：突出北京烤鸭的地域特色。\\n   - **金陵鸭香**：如果店铺在南京，可以突出金陵文化。\\n   - **蜀香鸭**：如果结合川味，可以突出麻辣风味。\\n   - **江南鸭韵**：适合南方风格的烤鸭店。\\n\\n### 5. **高端风格**\\n   - **御品鸭香**：高端大气，适合高档餐厅。\\n   - **金鸭阁**：带有奢华感，适合高端消费群体。\\n   - **皇家鸭宴**：突出皇家风范，适合高档餐厅。\\n   - **鸭香御府**：带有贵族气息，适合高端品牌。\\n\\n### 6. **趣味风格**\\n   - **鸭力山大**：谐音“压力山大”，轻松幽默。\\n   - **鸭香不怕胖**：幽默地表达烤鸭的美味，吸引年轻人。\\n   - **鸭香不怕晚**：适合夜宵或晚市，突出随时可以享受美味。\\n   - **鸭香不怕等**：突出烤鸭的美味值得等待。\\n\\n### 7. **结合店铺特色**\\n   - 如果店铺有独特的烤制工艺或秘方，可以在名字中体现，比如：\\n     - **秘制鸭香**\\n     - **炭火鸭香**\\n     - **果木烤鸭坊**\\n\\n### 8. **国际化风格**\\n   - **Duck Republic**（鸭之共和国）：适合国际化或现代风格的餐厅。\\n   - **Golden Duck**（金鸭）：简单直接，适合高端或国际化品牌。\\n   - **Peking Duck House**（北京烤鸭屋）：适合面向外国顾客的餐厅。\\n\\n### 取名小贴士：\\n- **简洁易记**：名字不要太复杂，方便顾客记住和传播。\\n- **突出特色**：名字要能体现烤鸭的美味或店铺的特色。\\n- **文化内涵**：可以结合中国传统文化或地域特色，增加品牌的文化底蕴。\\n- **避免雷同**：确保名字没有与其他品牌重复，避免法律纠纷。\\n\\n希望这些建议能帮助你找到一个合适的名字！'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "run_pipeline(\"烤鸭\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a5528b-9051-4b28-ac04-90579471650f",
      "metadata": {
        "id": "c2a5528b-9051-4b28-ac04-90579471650f",
        "outputId": "b1bb6a46-8f24-409b-8d3c-f9a24707f5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'给一家卖驴肉火烧的店取名时，既要突出特色，又要朗朗上口，容易让顾客记住。以下是一些建议：\\n\\n1. **驴香记**  \\n   突出驴肉的香味，简洁大气，容易让人联想到美味的驴肉火烧。\\n\\n2. **火烧驴坊**  \\n   直接点明店铺的主打产品，简单明了，容易吸引顾客。\\n\\n3. **驴火传奇**  \\n   给人一种历史悠久、品质上乘的感觉，适合想要打造品牌形象的店铺。\\n\\n4. **驴香四溢**  \\n   强调驴肉的香气，给人一种食欲感，适合吸引食客。\\n\\n5. **驴肉火烧王**  \\n   简单直接，突出店铺的专业性和权威性，适合想要打造“王者”形象的店铺。\\n\\n6. **驴香满堂**  \\n   给人一种热闹、丰盛的感觉，适合营造温馨的用餐氛围。\\n\\n7. **驴火飘香**  \\n   强调火烧的香气，吸引顾客进店品尝。\\n\\n8. **驴肉火烧铺**  \\n   简单直接，适合走亲民路线的店铺。\\n\\n9. **驴香坊**  \\n   简洁大方，突出驴肉的特色，适合小而精致的店铺。\\n\\n10. **驴火人家**  \\n    给人一种亲切感，适合想要营造家庭氛围的店铺。\\n\\n11. **驴香一品**  \\n    强调驴肉火烧的高品质，适合走高端路线的店铺。\\n\\n12. **驴火飘香坊**  \\n    结合了“驴火”和“飘香”，既突出产品，又让人联想到美味。\\n\\n13. **驴肉火烧世家**  \\n    给人一种传承已久的感觉，适合有历史背景的店铺。\\n\\n14. **驴香阁**  \\n    带有古典气息，适合想要打造文化氛围的店铺。\\n\\n15. **驴火香缘**  \\n    强调与顾客的缘分，适合想要营造温馨氛围的店铺。\\n\\n在选择名字时，建议结合店铺的定位、目标顾客群体以及店铺的风格，确保名字既能吸引顾客，又能传达出店铺的特色和理念。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "run_pipeline(\"驴肉火烧\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0ebb94-1e99-4ca4-95c2-1837eb326b20",
      "metadata": {
        "id": "7e0ebb94-1e99-4ca4-95c2-1837eb326b20"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c0c03173-5ead-4f9e-b6ed-d97cf21c0f56",
      "metadata": {
        "id": "c0c03173-5ead-4f9e-b6ed-d97cf21c0f56"
      },
      "source": [
        "## wrap_openai 客户端\n",
        "\n",
        "Python/TypeScript 中的 wrap_openai/wrapOpenAI 方法允许您包装 OpenAI 客户端，以便自动记录跟踪 - 无需装饰器或函数包装！\n",
        "\n",
        "该包装器与 @traceable 装饰器或可追溯函数完美配合，可以在同一应用程序中同时使用两者。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b3c43988-c21a-4de7-95a6-5c7d8c877d7e",
      "metadata": {
        "id": "b3c43988-c21a-4de7-95a6-5c7d8c877d7e",
        "outputId": "f2fa71a2-d1f0-4c47-b689-bc062a33969c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-fbb1344caa8e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 包装 OpenAI 客户端\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 标记函数可追踪，并指定运行类型为工具，名称为\"Retrieve Context\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from langsmith import traceable\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "# 包装 OpenAI 客户端\n",
        "client = wrap_openai(openai.Client())\n",
        "\n",
        "# 标记函数可追踪，并指定运行类型为工具，名称为\"Retrieve Context\"\n",
        "@traceable(run_type=\"tool\", name=\"Retrieve Context\")\n",
        "def my_tool(question: str) -> str:\n",
        "    # 返回上下文信息\n",
        "    return \"在今天早上的会议中，我们讨论了出海创业的机会与挑战。\"\n",
        "\n",
        "# 标记函数可追踪，名称为\"Chat Pipeline\"\n",
        "@traceable(name=\"Chat Pipeline\")\n",
        "def chat_pipeline(question: str):\n",
        "    # 获取上下文信息\n",
        "    context = my_tool(question)\n",
        "\n",
        "    # 创建消息列表，包含系统消息和用户消息\n",
        "    messages = [\n",
        "        { \"role\": \"system\", \"content\": \"你是一个乐于助人的助手。请仅根据给定的上下文回复用户的请求。\" },\n",
        "        { \"role\": \"user\", \"content\": f\"问题：{question}\\n上下文：{context}\"}\n",
        "    ]\n",
        "\n",
        "    # 调用聊天模型生成回复\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\", messages=messages\n",
        "    )\n",
        "\n",
        "    # 返回模型的回复内容\n",
        "    return chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f68fd0b1-42cf-41d6-80db-34ae698938c3",
      "metadata": {
        "id": "f68fd0b1-42cf-41d6-80db-34ae698938c3",
        "outputId": "86ddac8a-9652-4a63-e7b7-a18cab558efc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'当然！在今天早上的会议中，我们主要讨论了出海创业的机会与挑战。'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 调用 chat_pipeline 函数\n",
        "chat_pipeline(\"你能总结一下今天早上的会议吗？\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c492c03-0c06-4954-a771-842c1e69ab93",
      "metadata": {
        "id": "6c492c03-0c06-4954-a771-842c1e69ab93"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f69594a-ce78-460a-8f7c-234e71671af4",
      "metadata": {
        "id": "7f69594a-ce78-460a-8f7c-234e71671af4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "93f104da-4557-4a19-ab78-ccbc87a77fc3",
      "metadata": {
        "id": "93f104da-4557-4a19-ab78-ccbc87a77fc3"
      },
      "source": [
        "## RunTree API\n",
        "\n",
        "通过 RunTree API，是跟踪日志记录到 LangSmith 的另一种更直接的方式。\n",
        "\n",
        "该API允许对跟踪进行更多控制：可以手动创建运行和子运行以组装您的跟踪。\n",
        "\n",
        "您仍然需要设置LANGCHAIN_API_KEY，但对于**此方法不需要LANGCHAIN_TRACING_V2**。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b20cc85a-b244-46bb-9f60-ef1bc7dd6596",
      "metadata": {
        "id": "b20cc85a-b244-46bb-9f60-ef1bc7dd6596"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from langsmith.run_trees import RunTree\n",
        "\n",
        "# 用户输入的问题\n",
        "question = \"你能总结一下今天早上的会议吗？\"\n",
        "\n",
        "# 创建一个顶层的运行节点\n",
        "pipeline = RunTree(\n",
        "    name=\"Chat Pipeline\",\n",
        "    run_type=\"chain\",\n",
        "    inputs={\"question\": question}\n",
        ")\n",
        "\n",
        "# 在检索步骤中获取的上下文信息\n",
        "context = \"在今天早上的会议中，我们回顾了改革开放的重大成果。\"\n",
        "\n",
        "# 创建消息列表，包含系统消息和用户消息\n",
        "messages = [\n",
        "    { \"role\": \"system\", \"content\": \"你是一个乐于助人的助手。请仅根据给定的上下文回复用户的请求。\" },\n",
        "    { \"role\": \"user\", \"content\": f\"问题：{question}\\n上下文：{context}\"}\n",
        "]\n",
        "\n",
        "# 创建一个子运行节点\n",
        "child_llm_run = pipeline.create_child(\n",
        "    name=\"OpenAI Call\",\n",
        "    run_type=\"llm\",\n",
        "    inputs={\"messages\": messages},\n",
        ")\n",
        "\n",
        "# 生成回复\n",
        "client = openai.Client()\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\", messages=messages\n",
        ")\n",
        "\n",
        "# 结束子运行节点并记录输出\n",
        "child_llm_run.end(outputs=chat_completion)\n",
        "child_llm_run.post()\n",
        "\n",
        "# 结束顶层运行节点并记录输出\n",
        "pipeline.end(outputs={\"answer\": chat_completion.choices[0].message.content})\n",
        "pipeline.post()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db9551af-b355-4e1e-806a-d4a5f3391e8e",
      "metadata": {
        "id": "db9551af-b355-4e1e-806a-d4a5f3391e8e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f491ec79-ca16-43d1-bb35-104fdac70bc9",
      "metadata": {
        "id": "f491ec79-ca16-43d1-bb35-104fdac70bc9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ba406496-fbbb-422f-b2d4-41333c5232c5",
      "metadata": {
        "id": "ba406496-fbbb-422f-b2d4-41333c5232c5"
      },
      "source": [
        "## trace 上下文管理器\n",
        "\n",
        "在Python中，使用trace上下文管理器跟踪日志记录到LangSmith。在以下情况下非常有用：\n",
        "\n",
        "- 想要为特定代码块记录跟踪日志，而不设置一个会为整个应用程序记录跟踪的环境变量。\n",
        "- 希望对跟踪的输入、输出和其他属性进行控制。\n",
        "- 使用装饰器或包装器并不可行。\n",
        "\n",
        "该上下文管理器与可追溯的装饰器和 `wrap_openai` 包装器无缝集成，因此，可以在同一应用程序中同时使用它们。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21255c23-f9e4-4c96-b729-475cd8ae62f5",
      "metadata": {
        "id": "21255c23-f9e4-4c96-b729-475cd8ae62f5"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from langsmith import trace\n",
        "from langsmith import traceable\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "# 包装 OpenAI 客户端\n",
        "client = wrap_openai(openai.Client())\n",
        "\n",
        "# 标记函数可追踪，并指定运行类型为工具，名称为\"Retrieve Context\"\n",
        "@traceable(run_type=\"tool\", name=\"Retrieve Context\")\n",
        "def my_tool(question: str) -> str:\n",
        "    # 返回上下文信息\n",
        "    return \"During this morning's meeting, we solved all world conflict.\"\n",
        "\n",
        "def chat_pipeline(question: str):\n",
        "    # 获取上下文信息\n",
        "    context = my_tool(question)\n",
        "\n",
        "    # 创建消息列表，包含系统消息和用户消息\n",
        "    messages = [\n",
        "        { \"role\": \"system\", \"content\": \"你是一个乐于助人的助手。请仅根据给定的上下文回复用户的请求。\" },\n",
        "        { \"role\": \"user\", \"content\": f\"问题：{question}\\n上下文：{context}\"}\n",
        "    ]\n",
        "\n",
        "    # 调用聊天模型生成回复\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\", messages=messages\n",
        "    )\n",
        "\n",
        "    # 返回模型的回复内容\n",
        "    return chat_completion.choices[0].message.content\n",
        "\n",
        "# 应用输入\n",
        "app_inputs = {\"input\": \"Can you summarize this morning's meetings?\"}\n",
        "\n",
        "# 跟踪聊天管道运行\n",
        "with trace(\"Chat Pipeline\", \"chain\", project_name=\"my_test\", inputs=app_inputs) as rt:\n",
        "    output = chat_pipeline(\"Can you summarize this morning's meetings?\")\n",
        "    rt.end(outputs={\"output\": output})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c780ee8-10d8-4162-8a89-85f9aafa2ea5",
      "metadata": {
        "id": "9c780ee8-10d8-4162-8a89-85f9aafa2ea5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e0f0d4d9-dad9-49e6-8773-689435433923",
      "metadata": {
        "id": "e0f0d4d9-dad9-49e6-8773-689435433923"
      },
      "source": [
        "## 记录多模态模型 GPT-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f85113-0fe2-41c9-80e0-905fbf6d1b22",
      "metadata": {
        "id": "99f85113-0fe2-41c9-80e0-905fbf6d1b22"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "# 包装 OpenAI 客户端\n",
        "client = wrap_openai(OpenAI())\n",
        "\n",
        "# 调用聊天模型生成回复\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"介绍下这幅图讲的什么？\"},\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://p6.itc.cn/q_70/images03/20200602/0c267a0d3d814c9783659eb956969ba1.jpeg\",\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6661f6a-8d54-4fe4-96f8-8f0d046a719b",
      "metadata": {
        "id": "c6661f6a-8d54-4fe4-96f8-8f0d046a719b",
        "outputId": "2fe43468-222c-48e9-9b0d-8db64b3c3000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "这幅图是一种幽默搞笑的对比图。左侧展示的是一只形如肌肉男的柴犬，被称为“16岁的我”，右侧则是一只普通的柴犬，被称为“工作后的我”。图片通过夸张的肌肉和普通的狗的形态来幽默地表达了人们对比自己年轻时充满活力和成年后工作压力导致身体和精神状态“变形”的感受。左边的大肌肉柴犬下方的文字翻译为“我可以一口气做一百个俯卧撑，一条跑足十公里，浴火重生的女人，人见人爱的大男孩”，而右边的普通柴犬下方的文字翻译为“好累啊 好想赖床 浑身疼痛 我没有病 你心有病 我命由我不由天 独步天下”。这些标签富含讽刺和幽默意味，反映了现代生活中劳累与压力的普遍现象。\n"
          ]
        }
      ],
      "source": [
        "# 打印回复的内容\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf55450-6347-4d09-8b19-1c256709e0e8",
      "metadata": {
        "id": "4cf55450-6347-4d09-8b19-1c256709e0e8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9371b424-1510-44c5-a433-09b4822305f6",
      "metadata": {
        "id": "9371b424-1510-44c5-a433-09b4822305f6"
      },
      "source": [
        "## 结合 LangChain 记录追踪\n",
        "\n",
        "设置好以下环境变量后，无需任何额外的代码即可追踪 LangChain 运行\n",
        "```shell\n",
        "export LANGCHAIN_TRACING_V2=true\n",
        "export LANGCHAIN_API_KEY=<your-api-key>\n",
        "\n",
        "# The below examples use the OpenAI API, so you will need\n",
        "export OPENAI_API_KEY=<your-openai-api-key>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7f045a-5a65-4c3d-aa45-e415a38d62ab",
      "metadata": {
        "id": "cf7f045a-5a65-4c3d-aa45-e415a38d62ab"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 从消息中创建聊天提示模板\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"你是一个乐于助人的助手。请参考给定的上下文回复用户的请求。\"),\n",
        "    (\"user\", \"问题：{question}\\n上下文：{context}\")\n",
        "])\n",
        "\n",
        "# 使用指定的模型\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 将提示模板、模型和输出解析器链在一起\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "# 定义问题和上下文\n",
        "question = \"孙悟空到底打过几次白骨精啊？\"\n",
        "context = \"其实孙悟空三打白骨精后，又打了她一次\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcb18175-b9ef-40d4-b455-52be5f66028c",
      "metadata": {
        "id": "dcb18175-b9ef-40d4-b455-52be5f66028c",
        "outputId": "9258aa4f-0231-4138-8df2-9b850f69187a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'孙悟空一共打过四次白骨精。'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 调用链条并传递输入\n",
        "chain.invoke({\"question\": question, \"context\": context})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e6ea25-812c-43e7-906e-367429b3e7d1",
      "metadata": {
        "id": "03e6ea25-812c-43e7-906e-367429b3e7d1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}