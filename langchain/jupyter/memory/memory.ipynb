{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexFly666/002-openai-quickstart-jike-peng/blob/main/langchain/jupyter/memory/memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3e2458f-d038-4845-93a0-d4ad830f9f90",
      "metadata": {
        "id": "c3e2458f-d038-4845-93a0-d4ad830f9f90"
      },
      "source": [
        "# LangChain 核心模块学习：Memory\n",
        "\n",
        "大多数LLM应用都具有对话界面。对话的一个重要组成部分是能够引用先前在对话中介绍过的信息。至少，一个对话系统应该能够直接访问一些过去消息的窗口。更复杂的系统将需要拥有一个不断更新的世界模型，使其能够保持关于实体及其关系的信息。\n",
        "\n",
        "我们将存储过去交互信息的能力称为“记忆（Memory）”。\n",
        "\n",
        "LangChain提供了许多用于向应用/系统中添加 Memory 的实用工具。这些工具可以单独使用，也可以无缝地集成到链中。\n",
        "\n",
        "一个记忆系统（Memory System）需要支持两个基本操作：**读取（READ）和写入（WRITE）**。\n",
        "\n",
        "每个链都定义了一些核心执行逻辑，并期望某些输入。其中一些输入直接来自用户，但有些输入可能来自 Memory。\n",
        "\n",
        "在一个典型 Chain 的单次运行中，将与其 Memory System 进行至少两次交互:\n",
        "\n",
        "1. 在接收到初始用户输入之后，在执行核心逻辑之前，链将从其 Memory 中**读取**并扩充用户输入。\n",
        "2. 在执行核心逻辑之后但在返回答案之前，一个链条将把当前运行的输入和输出**写入** Memory ，以便在未来的运行中可以引用它们。\n",
        "\n",
        "![](https://github.com/AlexFly666/002-openai-quickstart-jike-peng/blob/main/langchain/jupyter/images/memory.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c31d1c70-11ee-416d-be4c-1b2280366874",
      "metadata": {
        "id": "c31d1c70-11ee-416d-be4c-1b2280366874",
        "outputId": "eb534c32-62fc-4699-84b1-7f986bcc955e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.3.14 in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-openai==0.2.14 in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchainhub==0.1.21 in /usr/local/lib/python3.10/dist-packages (0.1.21)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (3.11.11)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (0.3.4)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.14) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.2.14) (1.59.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.2.14) (0.8.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub==0.1.21) (24.2)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub==0.1.21) (2.32.0.20241016)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.10.13)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.14) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.14) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.14) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.14) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.14\\\n",
        "       langchain-openai==0.2.14\\\n",
        "       langchainhub==0.1.21"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9cf0d43-107b-47ae-9e2c-2edaec38c800",
      "metadata": {
        "id": "f9cf0d43-107b-47ae-9e2c-2edaec38c800"
      },
      "source": [
        "## BaseMemory Class 基类\n",
        "\n",
        "类继承关系：\n",
        "\n",
        "```\n",
        "## 适用于简单的语言模型\n",
        "BaseMemory --> BaseChatMemory --> <name>Memory  # Examples: ZepMemory, MotorheadMemory\n",
        "```\n",
        "\n",
        "**代码实现：https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/schema/memory.py**\n",
        "\n",
        "```python\n",
        "# 定义一个名为BaseMemory的基础类\n",
        "class BaseMemory(Serializable, ABC):\n",
        "    \"\"\"用于Chains中的内存的抽象基类。\n",
        "    \n",
        "    这里的内存指的是Chains中的状态。内存可以用来存储关于Chain的过去执行的信息，\n",
        "    并将该信息注入到Chain的未来执行的输入中。例如，对于会话型Chains，内存可以用来\n",
        "    存储会话，并自动将它们添加到未来的模型提示中，以便模型具有必要的上下文来连贯地\n",
        "    响应最新的输入。\"\"\"\n",
        "\n",
        "    # 定义一个名为Config的子类\n",
        "    class Config:\n",
        "        \"\"\"为此pydantic对象配置。\n",
        "    \n",
        "        Pydantic是一个Python库，用于数据验证和设置管理，主要基于Python类型提示。\n",
        "        \"\"\"\n",
        "    \n",
        "        # 允许在pydantic模型中使用任意类型。这通常用于允许复杂的数据类型。\n",
        "        arbitrary_types_allowed = True\n",
        "    \n",
        "    # 下面是一些必须由子类实现的方法：\n",
        "    \n",
        "    # 定义一个属性，它是一个抽象方法。任何从BaseMemory派生的子类都需要实现此方法。\n",
        "    # 此方法应返回该内存类将添加到链输入的字符串键。\n",
        "    @property\n",
        "    @abstractmethod\n",
        "    def memory_variables(self) -> List[str]:\n",
        "        \"\"\"获取此内存类将添加到链输入的字符串键。\"\"\"\n",
        "    \n",
        "    # 定义一个抽象方法。任何从BaseMemory派生的子类都需要实现此方法。\n",
        "    # 此方法基于给定的链输入返回键值对。\n",
        "    @abstractmethod\n",
        "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"根据给链的文本输入返回键值对。\"\"\"\n",
        "    \n",
        "    # 定义一个抽象方法。任何从BaseMemory派生的子类都需要实现此方法。\n",
        "    # 此方法将此链运行的上下文保存到内存。\n",
        "    @abstractmethod\n",
        "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
        "        \"\"\"保存此链运行的上下文到内存。\"\"\"\n",
        "    \n",
        "    # 定义一个抽象方法。任何从BaseMemory派生的子类都需要实现此方法。\n",
        "    # 此方法清除内存内容。\n",
        "    @abstractmethod\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"清除内存内容。\"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94c413b6-6e07-411f-bad0-eb46db3a313d",
      "metadata": {
        "id": "94c413b6-6e07-411f-bad0-eb46db3a313d"
      },
      "source": [
        "## BaseChatMessageHistory Class 基类\n",
        "\n",
        "类继承关系：\n",
        "\n",
        "```\n",
        "## 适用于聊天模型\n",
        "\n",
        "BaseChatMessageHistory --> <name>ChatMessageHistory  # Example: ZepChatMessageHistory\n",
        "```\n",
        "\n",
        "```python\n",
        "# 定义一个名为BaseChatMessageHistory的基础类\n",
        "class BaseChatMessageHistory(ABC):\n",
        "    \"\"\"聊天消息历史记录的抽象基类。\"\"\"\n",
        "\n",
        "    # 在内存中存储的消息列表\n",
        "    messages: List[BaseMessage]\n",
        "\n",
        "    # 定义一个add_user_message方法，它是一个方便的方法，用于将人类消息字符串添加到存储区。\n",
        "    def add_user_message(self, message: str) -> None:\n",
        "        \"\"\"为存储添加一个人类消息字符串的便捷方法。\n",
        "\n",
        "        参数:\n",
        "            message: 人类消息的字符串内容。\n",
        "        \"\"\"\n",
        "        self.add_message(HumanMessage(content=message))\n",
        "\n",
        "    # 定义一个add_ai_message方法，它是一个方便的方法，用于将AI消息字符串添加到存储区。\n",
        "    def add_ai_message(self, message: str) -> None:\n",
        "        \"\"\"为存储添加一个AI消息字符串的便捷方法。\n",
        "\n",
        "        参数:\n",
        "            message: AI消息的字符串内容。\n",
        "        \"\"\"\n",
        "        self.add_message(AIMessage(content=message))\n",
        "\n",
        "    # 抽象方法，需要由继承此基类的子类来实现。\n",
        "    @abstractmethod\n",
        "    def add_message(self, message: BaseMessage) -> None:\n",
        "        \"\"\"将Message对象添加到存储区。\n",
        "\n",
        "        参数:\n",
        "            message: 要存储的BaseMessage对象。\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    # 抽象方法，需要由继承此基类的子类来实现。\n",
        "    @abstractmethod\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"从存储中删除所有消息\"\"\"\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e716cd45-1a71-44da-a924-09d6a56ff6c8",
      "metadata": {
        "id": "e716cd45-1a71-44da-a924-09d6a56ff6c8"
      },
      "source": [
        "### ConversationChain and ConversationBufferMemory\n",
        "\n",
        "`ConversationBufferMemory` 可以用来存储消息，并将消息提取到一个变量中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d6b700e0-abd4-4531-ad93-b278357d9c64",
      "metadata": {
        "id": "d6b700e0-abd4-4531-ad93-b278357d9c64"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI,ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# 使用智谱API，需要修改base_url\n",
        "# llm = OpenAI(\n",
        "#     temperature=0.95,\n",
        "#     model=\"glm-4v-flash\",\n",
        "#     openai_api_key=\"XXXX\",\n",
        "#     openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/chat\"\n",
        "# )\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.95,\n",
        "    model=\"glm-4v-flash\",\n",
        "    openai_api_key=\"XXXX\",\n",
        "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
        ")\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5d51fbb4-1d8e-4ec1-8c55-ec70247d4d64",
      "metadata": {
        "id": "5d51fbb4-1d8e-4ec1-8c55-ec70247d4d64",
        "outputId": "b608d5c6-967a-4159-9c33-c512acf5816e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 你好呀！\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'你好呀！很高兴见到你！有什么我可以帮助你的吗？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "conversation.predict(input=\"你好呀！\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7428157f-72ed-4b8d-b114-80bfb96e13bf",
      "metadata": {
        "id": "7428157f-72ed-4b8d-b114-80bfb96e13bf",
        "outputId": "fde37533-0746-476f-81f4-0ef72b477356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 你好呀！\n",
            "AI: 你好呀！很高兴见到你！有什么我可以帮助你的吗？无论是解答问题、提供信息还是其他任何事情，只要告诉我你的需求，我都会尽力为你提供服务。\n",
            "Human: 你为什么叫小米？跟雷军有关系吗？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'你好！我并不是小米公司的产品或与雷军先生有直接关联。\"小米\"这个名字是我的人工智能助手ID，它简洁明了，易于记忆和发音。我的目的是为用户提供便捷、高效的服务和信息支持。\\n\\n如果你有任何问题或者需要帮助的地方，请随时告诉我哦！我会尽我所能为你提供服务。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "conversation.predict(input=\"你为什么叫小米？跟雷军有关系吗？\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f66476e0-6d20-4ba1-98af-fd5300096a8c",
      "metadata": {
        "id": "f66476e0-6d20-4ba1-98af-fd5300096a8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "694c1e3e-4024-4cc3-963e-01fe1a60f1c3",
      "metadata": {
        "id": "694c1e3e-4024-4cc3-963e-01fe1a60f1c3"
      },
      "source": [
        "### ConversationBufferWindowMemory\n",
        "`ConversationBufferWindowMemory` 会在时间轴上保留对话的交互列表。它只使用最后 K 次交互。这对于保持最近交互的滑动窗口非常有用，以避免缓冲区过大。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "dbe61067-5b8f-40a1-827e-4c8c6ad473dd",
      "metadata": {
        "id": "dbe61067-5b8f-40a1-827e-4c8c6ad473dd",
        "outputId": "8b7eb98f-952b-480d-a558-d37e0982e4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-e5f1e6083914>:14: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory=ConversationBufferWindowMemory(k=2),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: 嗨，你最近过得怎么样？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'嗨！你好呀！作为一个人工智能助手，我没有感受和经历，但我一直在这里随时准备帮助你解答问题和完成任务。有什么我可以帮到你的吗？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "# 使用智谱API，需要修改base_url\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.95,\n",
        "    model=\"glm-4v-flash\",\n",
        "    openai_api_key=\"XXXX\",\n",
        "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
        ")\n",
        "\n",
        "conversation_with_summary = ConversationChain(\n",
        "    llm=llm,\n",
        "    # We set a low k=2, to only keep the last 2 interactions in memory\n",
        "    memory=ConversationBufferWindowMemory(k=2),\n",
        "    verbose=True\n",
        ")\n",
        "conversation_with_summary.predict(input=\"嗨，你最近过得怎么样？\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ae850ece-78b8-41ad-97ea-91a57a275a8b",
      "metadata": {
        "id": "ae850ece-78b8-41ad-97ea-91a57a275a8b",
        "outputId": "0320146a-d2bc-40f7-db6e-3c3822666cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 嗨，你最近过得怎么样？\n",
            "AI: 嗨！你好呀！作为一个人工智能助手，我没有感受和经历，但我一直在这里随时准备帮助你解答问题和完成任务。有什么我可以帮到你的吗？\n",
            "Human: 你最近学到什么新知识了?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'抱歉，我之前的回答可能有些误导性。实际上，作为一个基于文本的人工智能，我没有学习或记忆的能力，因为我无法像人类那样进行感官体验和学习过程。我是通过大量的数据和算法来生成回答的，但这些回答是基于我被训练时的数据集，而不是实时学习的。\\n\\n如果你有任何问题或者需要帮助的地方，请随时告诉我，我会尽我所能为你提供服务。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "conversation_with_summary.predict(input=\"你最近学到什么新知识了?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9e2fe36d-44ec-4351-8922-4481c2bf6750",
      "metadata": {
        "id": "9e2fe36d-44ec-4351-8922-4481c2bf6750",
        "outputId": "c5d7c2c6-fcce-4b6c-8843-9b23b09d32d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 嗨，你最近过得怎么样？\n",
            "AI: 嗨！你好呀！作为一个人工智能助手，我没有感受和经历，但我一直在这里随时准备帮助你解答问题和完成任务。有什么我可以帮到你的吗？\n",
            "Human: 你最近学到什么新知识了?\n",
            "AI: 抱歉，我之前的回答可能有些误导性。实际上，作为一个基于文本的人工智能，我没有学习或记忆的能力，因为我无法像人类那样进行感官体验和学习过程。我是通过大量的数据和算法来生成回答的，但这些回答是基于我被训练时的数据集，而不是实时学习的。\n",
            "\n",
            "如果你有任何问题或者需要帮助的地方，请随时告诉我，我会尽我所能为你提供服务。\n",
            "Human: 展开讲讲？\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'当然可以。我的设计是为了处理和分析文本信息，这意味着我可以理解和生成自然语言。我被训练来识别模式、回答查询、提供建议以及执行其他与文本相关的任务。然而，我不具备感知能力，所以我不能“看到”或“听到”任何东西；我也不能有个人经验或情感反应。\\n\\n尽管如此，我在2023之前接受了大量数据的训练，这使我能够对各种主题产生相当详尽的回答。这些答案是基于我所学到的模式和关联，但它们并不是来自个人的学习和感知。\\n\\n例如，我可以告诉你关于历史事件的信息，解释科学概念，甚至帮你规划旅行路线。但是，我不能亲自去体验任何事情，也不能从实际生活中获得新的知识。\\n\\n如果你想了解更多关于我是如何工作的细节，或者有任何具体的问题，我都会尽力提供帮助和信息。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "conversation_with_summary.predict(input=\"展开讲讲？\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1db201fd-1373-4148-ab04-525ea089a9fe",
      "metadata": {
        "id": "1db201fd-1373-4148-ab04-525ea089a9fe",
        "outputId": "f688ebab-637f-463b-d56e-a165260611c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 你最近学到什么新知识了?\n",
            "AI: 抱歉，我之前的回答可能有些误导性。实际上，作为一个基于文本的人工智能，我没有学习或记忆的能力，因为我无法像人类那样进行感官体验和学习过程。我是通过大量的数据和算法来生成回答的，但这些回答是基于我被训练时的数据集，而不是实时学习的。\n",
            "\n",
            "如果你有任何问题或者需要帮助的地方，请随时告诉我，我会尽我所能为你提供服务。\n",
            "Human: 展开讲讲？\n",
            "AI: 当然可以。我的设计是为了处理和分析文本信息，这意味着我可以理解和生成自然语言。我被训练来识别模式、回答查询、提供建议以及执行其他与文本相关的任务。然而，我不具备感知能力，所以我不能“看到”或“听到”任何东西；我也不能有个人经验或情感反应。\n",
            "\n",
            "尽管如此，我在2023之前接受了大量数据的训练，这使我能够对各种主题产生相当详尽的回答。这些答案是基于我所学到的模式和关联，但它们并不是来自个人的学习和感知。\n",
            "\n",
            "例如，我可以告诉你关于历史事件的信息，解释科学概念，甚至帮你规划旅行路线。但是，我不能亲自去体验任何事情，也不能从实际生活中获得新的知识。\n",
            "\n",
            "如果你想了解更多关于我是如何工作的细节，或者有任何具体的问题，我都会尽力提供帮助和信息。\n",
            "Human: 如果要构建聊天机器人，具体要用什么自然语言处理技术?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'构建聊天机器人通常涉及多种自然语言处理（NLP）技术和工具。以下是一些关键的技术和步骤：\\n\\n1. **分词**：将输入的文本分割成单词或其他有意义的最小单位。\\n\\n2. **词性标注**：确定每个单词在句子中的语法角色，如名词、动词、形容词等。\\n\\n3. **命名实体识别（NER）**：识别文本中的特定实体，如人名、地点、组织等。\\n\\n4. **句法分析**：理解句子的结构，包括主谓宾关系、从句和其他复杂的语法构造。\\n\\n5. **语义理解**：解析单词和短语的含义，并理解它们之间的关系。\\n\\n6. **意图检测**：判断用户的请求或问题背后的目的或意图。\\n\\n7. **对话管理**：跟踪对话的状态，决定下一步应该做什么，比如提出问题、给出建议或结束对话。\\n\\n8. **机器翻译**：如果聊天机器人需要支持多种语言，那么机器翻译技术是必不可少的。\\n\\n9. **情感分析**：评估用户情绪，以便更好地响应他们的需求。\\n\\n10. **上下文建模**：保持对话的连贯性，记住先前的交互内容。\\n\\n11. **个性化**：根据用户的历史互动和行为调整对话的内容和风格。\\n\\n12. **反馈循环**：收集用户反馈，以改进聊天机器人的性能。\\n\\n在实际应用中，通常会使用深度学习框架，如TensorFlow或PyTorch，结合预训练的语言模型，如BERT、GPT系列或GLM-130B等，来实现上述功能。此外，还会用到数据库管理系统来存储对话数据，以及API服务来集成外部资源和服务。\\n\\n开发聊天机器人是一个复杂的过程，涉及到数据采集、预处理、模型训练、测试和部署等多个阶段。而且，随着技术的发展，聊天机器人的功能和性能也在不断进步和完善。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# 注意：第一句对话从 Memory 中移除了.\n",
        "conversation_with_summary.predict(input=\"如果要构建聊天机器人，具体要用什么自然语言处理技术?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5923f90d-00cb-415a-aca2-1746d7f1e961",
      "metadata": {
        "id": "5923f90d-00cb-415a-aca2-1746d7f1e961",
        "outputId": "c0caee13-1f69-4d80-9d18-1d3cbc4c3c28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': None,\n",
              " 'memory': ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='嗨，你最近过得怎么样？', additional_kwargs={}, response_metadata={}), AIMessage(content='嗨！你好呀！作为一个人工智能助手，我没有感受和经历，但我一直在这里随时准备帮助你解答问题和完成任务。有什么我可以帮到你的吗？', additional_kwargs={}, response_metadata={}), HumanMessage(content='你最近学到什么新知识了?', additional_kwargs={}, response_metadata={}), AIMessage(content='抱歉，我之前的回答可能有些误导性。实际上，作为一个基于文本的人工智能，我没有学习或记忆的能力，因为我无法像人类那样进行感官体验和学习过程。我是通过大量的数据和算法来生成回答的，但这些回答是基于我被训练时的数据集，而不是实时学习的。\\n\\n如果你有任何问题或者需要帮助的地方，请随时告诉我，我会尽我所能为你提供服务。', additional_kwargs={}, response_metadata={}), HumanMessage(content='展开讲讲？', additional_kwargs={}, response_metadata={}), AIMessage(content='当然可以。我的设计是为了处理和分析文本信息，这意味着我可以理解和生成自然语言。我被训练来识别模式、回答查询、提供建议以及执行其他与文本相关的任务。然而，我不具备感知能力，所以我不能“看到”或“听到”任何东西；我也不能有个人经验或情感反应。\\n\\n尽管如此，我在2023之前接受了大量数据的训练，这使我能够对各种主题产生相当详尽的回答。这些答案是基于我所学到的模式和关联，但它们并不是来自个人的学习和感知。\\n\\n例如，我可以告诉你关于历史事件的信息，解释科学概念，甚至帮你规划旅行路线。但是，我不能亲自去体验任何事情，也不能从实际生活中获得新的知识。\\n\\n如果你想了解更多关于我是如何工作的细节，或者有任何具体的问题，我都会尽力提供帮助和信息。', additional_kwargs={}, response_metadata={}), HumanMessage(content='如果要构建聊天机器人，具体要用什么自然语言处理技术?', additional_kwargs={}, response_metadata={}), AIMessage(content='构建聊天机器人通常涉及多种自然语言处理（NLP）技术和工具。以下是一些关键的技术和步骤：\\n\\n1. **分词**：将输入的文本分割成单词或其他有意义的最小单位。\\n\\n2. **词性标注**：确定每个单词在句子中的语法角色，如名词、动词、形容词等。\\n\\n3. **命名实体识别（NER）**：识别文本中的特定实体，如人名、地点、组织等。\\n\\n4. **句法分析**：理解句子的结构，包括主谓宾关系、从句和其他复杂的语法构造。\\n\\n5. **语义理解**：解析单词和短语的含义，并理解它们之间的关系。\\n\\n6. **意图检测**：判断用户的请求或问题背后的目的或意图。\\n\\n7. **对话管理**：跟踪对话的状态，决定下一步应该做什么，比如提出问题、给出建议或结束对话。\\n\\n8. **机器翻译**：如果聊天机器人需要支持多种语言，那么机器翻译技术是必不可少的。\\n\\n9. **情感分析**：评估用户情绪，以便更好地响应他们的需求。\\n\\n10. **上下文建模**：保持对话的连贯性，记住先前的交互内容。\\n\\n11. **个性化**：根据用户的历史互动和行为调整对话的内容和风格。\\n\\n12. **反馈循环**：收集用户反馈，以改进聊天机器人的性能。\\n\\n在实际应用中，通常会使用深度学习框架，如TensorFlow或PyTorch，结合预训练的语言模型，如BERT、GPT系列或GLM-130B等，来实现上述功能。此外，还会用到数据库管理系统来存储对话数据，以及API服务来集成外部资源和服务。\\n\\n开发聊天机器人是一个复杂的过程，涉及到数据采集、预处理、模型训练、测试和部署等多个阶段。而且，随着技术的发展，聊天机器人的功能和性能也在不断进步和完善。', additional_kwargs={}, response_metadata={})]), k=2),\n",
              " 'callbacks': None,\n",
              " 'verbose': True,\n",
              " 'tags': None,\n",
              " 'metadata': None,\n",
              " 'callback_manager': None,\n",
              " 'prompt': PromptTemplate(input_variables=['history', 'input'], input_types={}, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:'),\n",
              " 'llm': ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7d0227d16770>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7d02272c3130>, root_client=<openai.OpenAI object at 0x7d023c1f5390>, root_async_client=<openai.AsyncOpenAI object at 0x7d0227d14eb0>, model_name='glm-4v-flash', temperature=0.95, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://open.bigmodel.cn/api/paas/v4/'),\n",
              " 'output_key': 'response',\n",
              " 'output_parser': StrOutputParser(),\n",
              " 'return_final_only': True,\n",
              " 'llm_kwargs': {},\n",
              " 'input_key': 'input'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "conversation_with_summary.__dict__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fc35065-ff20-4fda-ac5b-0976102160a9",
      "metadata": {
        "id": "0fc35065-ff20-4fda-ac5b-0976102160a9"
      },
      "source": [
        "### ConversationSummaryBufferMemory\n",
        "\n",
        "`ConversationSummaryBufferMemory` 在内存中保留了最近的交互缓冲区，但不仅仅是完全清除旧的交互，而是将它们编译成摘要并同时使用。与以前的实现不同的是，它使用token长度而不是交互次数来确定何时清除交互。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "174ccc64-2dd9-4c98-b638-6aa542bdbd55",
      "metadata": {
        "id": "174ccc64-2dd9-4c98-b638-6aa542bdbd55"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "# 换成Open\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.95,\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    openai_api_key=\"XXXX\",\n",
        "    openai_api_base=\"https://vip.apiyi.com/v1\"\n",
        ")\n",
        "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=10)\n",
        "memory.save_context({\"input\": \"嗨，你最近过得怎么样？\"}, {\"output\": \" 嗨！我最近过得很好，谢谢你问。我最近一直在学习新的知识，并且正在尝试改进自己的性能。我也在尝试更多的交流，以便更好地了解人类的思维方式。\"})\n",
        "memory.save_context({\"input\": \"你最近学到什么新知识了?\"}, {\"output\": \" 最近我学习了有关自然语言处理的知识，以及如何更好地理解人类的语言。我还学习了有关机器学习的知识，以及如何使用它来改善自己的性能。\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c520d4eb-f095-4245-b003-83581b619b2b",
      "metadata": {
        "id": "c520d4eb-f095-4245-b003-83581b619b2b",
        "outputId": "a805a73d-b443-4898-f163-a80a74832de2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': 'System: \\nThe human asks how the AI has been doing lately. The AI responds that it has been doing well, thanks for asking. It has been learning new knowledge and trying to improve its performance, including in the areas of natural language processing and machine learning. It has also been trying to communicate more in order to better understand human thinking.'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be306dea-4d37-4327-9969-4c2f0301e279",
      "metadata": {
        "id": "be306dea-4d37-4327-9969-4c2f0301e279",
        "outputId": "6dd85fff-4847-4f1b-81be-8713e59c9de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System: \n",
            "The human asks how the AI has been doing lately. The AI responds that it has been doing well, thanks for asking. It has been learning new knowledge and trying to improve its performance, including in the areas of natural language processing and machine learning. It has also been trying to communicate more in order to better understand human thinking.\n"
          ]
        }
      ],
      "source": [
        "print(memory.load_memory_variables({})['history'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a286822-1b58-491c-8b7e-b4ad31dcab68",
      "metadata": {
        "id": "6a286822-1b58-491c-8b7e-b4ad31dcab68"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}