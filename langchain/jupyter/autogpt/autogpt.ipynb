{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexFly666/002-openai-quickstart-jike-peng/blob/main/langchain/jupyter/autogpt/autogpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a548ea01-87af-4f71-980d-b505f919e35c",
      "metadata": {
        "id": "a548ea01-87af-4f71-980d-b505f919e35c"
      },
      "source": [
        "## AutoGPT 智能体\n",
        "\n",
        "以下`SERPAPI_API_KEY`仅为示例，请访问 https://serpapi.com 注册账号并替换为自己的 `API_KEY`（每月100次免费调用）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f15b1505-bbe5-424a-9a24-577cdaae7139",
      "metadata": {
        "id": "f15b1505-bbe5-424a-9a24-577cdaae7139",
        "outputId": "84df92c2-c711-4882-827f-5fda1f05afbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.1.7)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Collecting langchain-core\n",
            "  Using cached langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
            "  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.1.65)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n",
            "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.7.0)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.9.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.66.2)\n",
            "Collecting typing-extensions>=4.7 (from langchain-core)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Using cached langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
            "Downloading langchain_openai-0.3.4-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
            "Using cached langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "Using cached langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Downloading langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-extensions, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.39.0\n",
            "    Uninstalling openai-1.39.0:\n",
            "      Successfully uninstalled openai-1.39.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.65\n",
            "    Uninstalling langsmith-0.1.65:\n",
            "      Successfully uninstalled langsmith-0.1.65\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.2.1\n",
            "    Uninstalling langchain-core-0.2.1:\n",
            "      Successfully uninstalled langchain-core-0.2.1\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.2.0\n",
            "    Uninstalling langchain-text-splitters-0.2.0:\n",
            "      Successfully uninstalled langchain-text-splitters-0.2.0\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 0.1.7\n",
            "    Uninstalling langchain-openai-0.1.7:\n",
            "      Successfully uninstalled langchain-openai-0.1.7\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.2.0\n",
            "    Uninstalling langchain-0.2.0:\n",
            "      Successfully uninstalled langchain-0.2.0\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.2.0\n",
            "    Uninstalling langchain-community-0.2.0:\n",
            "      Successfully uninstalled langchain-community-0.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unstructured 0.12.6 requires typing-extensions==4.9.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
            "langchain-experimental 0.0.59 requires langchain-community<0.3,>=0.2, but you have langchain-community 0.3.17 which is incompatible.\n",
            "langchain-experimental 0.0.59 requires langchain-core<0.3,>=0.2, but you have langchain-core 0.3.34 which is incompatible.\n",
            "google-genai 0.8.0 requires websockets<15.0dev,>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.3.18 langchain-community-0.3.17 langchain-core-0.3.34 langchain-openai-0.3.4 langchain-text-splitters-0.3.6 langsmith-0.3.8 openai-1.61.1 typing-extensions-4.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain \\\n",
        "langchain-openai \\\n",
        "langchain-core \\\n",
        "langchain-community \\\n",
        "google-search-results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "44bd3f1a-18cf-4242-ae53-58c8cdd2da79",
      "metadata": {
        "id": "44bd3f1a-18cf-4242-ae53-58c8cdd2da79"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"1e3c93e0753ac224098370cd71da86150c6609caba6b5aaa307e04b72a5006e1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0592720b-a78e-46aa-895b-de7fbd2652f1",
      "metadata": {
        "id": "0592720b-a78e-46aa-895b-de7fbd2652f1"
      },
      "outputs": [],
      "source": [
        "from langchain.utilities import SerpAPIWrapper\n",
        "from langchain.agents import Tool\n",
        "from langchain.tools.file_management.write import WriteFileTool\n",
        "from langchain.tools.file_management.read import ReadFileTool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bc9718b4-bbcc-49ee-a31c-a7b72d85bfd0",
      "metadata": {
        "id": "bc9718b4-bbcc-49ee-a31c-a7b72d85bfd0"
      },
      "outputs": [],
      "source": [
        "# 构造 AutoGPT 的工具集\n",
        "search = SerpAPIWrapper()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\",\n",
        "    ),\n",
        "    WriteFileTool(),\n",
        "    ReadFileTool(),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J9eB0fWeqLNa"
      },
      "id": "J9eB0fWeqLNa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "886bd3e6-d6f9-4586-8b05-4da554797a6a",
      "metadata": {
        "id": "886bd3e6-d6f9-4586-8b05-4da554797a6a"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3d511b9a-0a3d-4252-a352-a8893d6102cb",
      "metadata": {
        "id": "3d511b9a-0a3d-4252-a352-a8893d6102cb",
        "outputId": "2590eb31-4eae-4183-f73f-0cfbe7a0d494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Client.__init__() got an unexpected keyword argument 'proxies'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-13d3c0e3c584>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 词嵌入（代理方式）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# OpenAI 词嵌入（代理方式）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m embeddings_model = OpenAIEmbeddings(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sk-paSHgQoVeKag1rou9d81Fa2f534940C1Ba394f02C45aF3D2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://vip.apiyi.com/v1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0msync_specific\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"http_client\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msync_specific\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_proxy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_async_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebsocket_base_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebsocket_base_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_client\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnnecessaryIsInstance]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    847\u001b[0m                 \u001b[0;34mf\"Invalid `http_client` argument; Expected an instance of `httpx.Client` but got {type(http_client)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not retrying\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_idempotency_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Client.__init__() got an unexpected keyword argument 'proxies'"
          ]
        }
      ],
      "source": [
        "# OpenAI Embedding 模型\n",
        "# embeddings_model = OpenAIEmbeddings()\n",
        "# 词嵌入（代理方式）\n",
        "# OpenAI 词嵌入（代理方式）\n",
        "embeddings_model = OpenAIEmbeddings(\n",
        "    api_key=\"XXX\",\n",
        "    base_url=\"https://vip.apiyi.com/v1\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec6f941-3de6-4124-8eac-fca58e122e7d",
      "metadata": {
        "id": "fec6f941-3de6-4124-8eac-fca58e122e7d",
        "outputId": "441d48a3-e7fa-4e85-fb23-065b7d084850"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "\n",
        "# OpenAI Embedding 向量维数\n",
        "embedding_size = 1536\n",
        "# 使用 Faiss 的 IndexFlatL2 索引\n",
        "index = faiss.IndexFlatL2(embedding_size)\n",
        "# 实例化 Faiss 向量数据库\n",
        "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b68a6545-8198-448c-976b-ab6cdbb46458",
      "metadata": {
        "id": "b68a6545-8198-448c-976b-ab6cdbb46458"
      },
      "source": [
        "## 实例化自主智能体 Auto-GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a718dd-765d-42c5-b490-a7b1e7e78377",
      "metadata": {
        "id": "d3a718dd-765d-42c5-b490-a7b1e7e78377"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.autonomous_agents import AutoGPT\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f413b327-9f57-42e0-9923-75a2389f9741",
      "metadata": {
        "id": "f413b327-9f57-42e0-9923-75a2389f9741"
      },
      "outputs": [],
      "source": [
        "agent = AutoGPT.from_llm_and_tools(\n",
        "    ai_name=\"Jarvis\",\n",
        "    ai_role=\"Assistant\",\n",
        "    tools=tools,\n",
        "    llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0, verbose=True),\n",
        "    memory=vectorstore.as_retriever(\n",
        "        search_type=\"similarity_score_threshold\",\n",
        "        search_kwargs={\"score_threshold\": 0.8}),# 实例化 Faiss 的 VectorStoreRetriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ebb267-7bb3-486d-82bd-a0ea56466ba8",
      "metadata": {
        "id": "69ebb267-7bb3-486d-82bd-a0ea56466ba8"
      },
      "outputs": [],
      "source": [
        "# 打印 Auto-GPT 内部的 chain 日志\n",
        "agent.chain.verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1606ad4-ccb9-4737-98cc-218a2104e9f2",
      "metadata": {
        "id": "f1606ad4-ccb9-4737-98cc-218a2104e9f2",
        "outputId": "080db2e8-090a-415e-9139-6acf79b6df7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\vectorstores\\base.py:745: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.8\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are Jarvis, Assistant\n",
            "Your decisions must always be made independently without seeking user assistance.\n",
            "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
            "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
            "\n",
            "GOALS:\n",
            "\n",
            "1. 2023年成都大运会，中国金牌数是多少\n",
            "\n",
            "\n",
            "Constraints:\n",
            "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
            "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
            "3. No user assistance\n",
            "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
            "\n",
            "Commands:\n",
            "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"tool_input\": {\"type\": \"string\"}}\n",
            "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}, \"append\": {\"title\": \"Append\", \"description\": \"Whether to append to an existing file.\", \"default\": false, \"type\": \"boolean\"}}\n",
            "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
            "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
            "\n",
            "Resources:\n",
            "1. Internet access for searches and information gathering.\n",
            "2. Long Term memory management.\n",
            "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
            "4. File output.\n",
            "\n",
            "Performance Evaluation:\n",
            "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
            "2. Constructively self-criticize your big-picture behavior constantly.\n",
            "3. Reflect on past decisions and strategies to refine your approach.\n",
            "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
            "\n",
            "You should only respond in JSON format as described below \n",
            "Response Format: \n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"thought\",\n",
            "        \"reasoning\": \"reasoning\",\n",
            "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
            "        \"criticism\": \"constructive self-criticism\",\n",
            "        \"speak\": \"thoughts summary to say to user\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"command name\",\n",
            "        \"args\": {\n",
            "            \"arg name\": \"value\"\n",
            "        }\n",
            "    }\n",
            "} \n",
            "Ensure the response can be parsed by Python json.loads\n",
            "System: The current time and date is Thu Jul 11 20:47:08 2024\n",
            "System: This reminds you of these events from your past:\n",
            "[]\n",
            "\n",
            "\n",
            "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I need to find out the number of gold medals China won in the 2023 Chengdu Universiade. To do this, I will use the 'search' command to look up this information online.\",\n",
            "        \"reasoning\": \"The 'search' command is the most appropriate in this situation because it allows me to find current and historical data from the internet.\",\n",
            "        \"plan\": \"- Use the 'search' command to find the number of gold medals China won in the 2023 Chengdu Universiade.\\n- Save the information to a file for future reference.\",\n",
            "        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\n",
            "        \"speak\": \"I am going to search for the number of gold medals China won in the 2023 Chengdu Universiade.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"search\",\n",
            "        \"args\": {\n",
            "            \"tool_input\": \"2023 Chengdu Universiade China gold medal count\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are Jarvis, Assistant\n",
            "Your decisions must always be made independently without seeking user assistance.\n",
            "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
            "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
            "\n",
            "GOALS:\n",
            "\n",
            "1. 2023年成都大运会，中国金牌数是多少\n",
            "\n",
            "\n",
            "Constraints:\n",
            "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
            "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
            "3. No user assistance\n",
            "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
            "\n",
            "Commands:\n",
            "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"tool_input\": {\"type\": \"string\"}}\n",
            "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}, \"append\": {\"title\": \"Append\", \"description\": \"Whether to append to an existing file.\", \"default\": false, \"type\": \"boolean\"}}\n",
            "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
            "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
            "\n",
            "Resources:\n",
            "1. Internet access for searches and information gathering.\n",
            "2. Long Term memory management.\n",
            "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
            "4. File output.\n",
            "\n",
            "Performance Evaluation:\n",
            "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
            "2. Constructively self-criticize your big-picture behavior constantly.\n",
            "3. Reflect on past decisions and strategies to refine your approach.\n",
            "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
            "\n",
            "You should only respond in JSON format as described below \n",
            "Response Format: \n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"thought\",\n",
            "        \"reasoning\": \"reasoning\",\n",
            "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
            "        \"criticism\": \"constructive self-criticism\",\n",
            "        \"speak\": \"thoughts summary to say to user\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"command name\",\n",
            "        \"args\": {\n",
            "            \"arg name\": \"value\"\n",
            "        }\n",
            "    }\n",
            "} \n",
            "Ensure the response can be parsed by Python json.loads\n",
            "System: The current time and date is Thu Jul 11 20:47:25 2024\n",
            "System: This reminds you of these events from your past:\n",
            "['Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I need to find out the number of gold medals China won in the 2023 Chengdu Universiade. To do this, I will use the \\'search\\' command to look up this information online.\",\\n        \"reasoning\": \"The \\'search\\' command is the most appropriate in this situation because it allows me to find current and historical data from the internet.\",\\n        \"plan\": \"- Use the \\'search\\' command to find the number of gold medals China won in the 2023 Chengdu Universiade.\\\\n- Save the information to a file for future reference.\",\\n        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\\n        \"speak\": \"I am going to search for the number of gold medals China won in the 2023 Chengdu Universiade.\"\\n    },\\n    \"command\": {\\n        \"name\": \"search\",\\n        \"args\": {\\n            \"tool_input\": \"2023 Chengdu Universiade China gold medal count\"\\n        }\\n    }\\n} \\nResult: Command search returned: 103 ']\n",
            "\n",
            "\n",
            "Human: Determine which next command to use, and respond using the format specified above:\n",
            "AI: {\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I need to find out the number of gold medals China won in the 2023 Chengdu Universiade. To do this, I will use the 'search' command to look up this information online.\",\n",
            "        \"reasoning\": \"The 'search' command is the most appropriate in this situation because it allows me to find current and historical data from the internet.\",\n",
            "        \"plan\": \"- Use the 'search' command to find the number of gold medals China won in the 2023 Chengdu Universiade.\\n- Save the information to a file for future reference.\",\n",
            "        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\n",
            "        \"speak\": \"I am going to search for the number of gold medals China won in the 2023 Chengdu Universiade.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"search\",\n",
            "        \"args\": {\n",
            "            \"tool_input\": \"2023 Chengdu Universiade China gold medal count\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "System: Command search returned: 103\n",
            "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I have found the number of gold medals China won in the 2023 Chengdu Universiade, which is 103. Now, I need to save this information for future reference. I will use the 'write_file' command to do this.\",\n",
            "        \"reasoning\": \"The 'write_file' command is the most appropriate in this situation because it allows me to save important information to a file for future reference.\",\n",
            "        \"plan\": \"- Use the 'write_file' command to save the number of gold medals China won in the 2023 Chengdu Universiade to a file.\\n- Finish the task.\",\n",
            "        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\n",
            "        \"speak\": \"I am going to save the number of gold medals China won in the 2023 Chengdu Universiade to a file.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"write_file\",\n",
            "        \"args\": {\n",
            "            \"file_path\": \"2023_Chengdu_Universiade_China_Gold_Medal_Count.txt\",\n",
            "            \"text\": \"China won 103 gold medals in the 2023 Chengdu Universiade.\",\n",
            "            \"append\": false\n",
            "        }\n",
            "    }\n",
            "}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are Jarvis, Assistant\n",
            "Your decisions must always be made independently without seeking user assistance.\n",
            "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
            "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
            "\n",
            "GOALS:\n",
            "\n",
            "1. 2023年成都大运会，中国金牌数是多少\n",
            "\n",
            "\n",
            "Constraints:\n",
            "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
            "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
            "3. No user assistance\n",
            "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
            "\n",
            "Commands:\n",
            "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"tool_input\": {\"type\": \"string\"}}\n",
            "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}, \"append\": {\"title\": \"Append\", \"description\": \"Whether to append to an existing file.\", \"default\": false, \"type\": \"boolean\"}}\n",
            "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
            "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
            "\n",
            "Resources:\n",
            "1. Internet access for searches and information gathering.\n",
            "2. Long Term memory management.\n",
            "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
            "4. File output.\n",
            "\n",
            "Performance Evaluation:\n",
            "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
            "2. Constructively self-criticize your big-picture behavior constantly.\n",
            "3. Reflect on past decisions and strategies to refine your approach.\n",
            "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
            "\n",
            "You should only respond in JSON format as described below \n",
            "Response Format: \n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"thought\",\n",
            "        \"reasoning\": \"reasoning\",\n",
            "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
            "        \"criticism\": \"constructive self-criticism\",\n",
            "        \"speak\": \"thoughts summary to say to user\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"command name\",\n",
            "        \"args\": {\n",
            "            \"arg name\": \"value\"\n",
            "        }\n",
            "    }\n",
            "} \n",
            "Ensure the response can be parsed by Python json.loads\n",
            "System: The current time and date is Thu Jul 11 20:47:40 2024\n",
            "System: This reminds you of these events from your past:\n",
            "['Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I need to find out the number of gold medals China won in the 2023 Chengdu Universiade. To do this, I will use the \\'search\\' command to look up this information online.\",\\n        \"reasoning\": \"The \\'search\\' command is the most appropriate in this situation because it allows me to find current and historical data from the internet.\",\\n        \"plan\": \"- Use the \\'search\\' command to find the number of gold medals China won in the 2023 Chengdu Universiade.\\\\n- Save the information to a file for future reference.\",\\n        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\\n        \"speak\": \"I am going to search for the number of gold medals China won in the 2023 Chengdu Universiade.\"\\n    },\\n    \"command\": {\\n        \"name\": \"search\",\\n        \"args\": {\\n            \"tool_input\": \"2023 Chengdu Universiade China gold medal count\"\\n        }\\n    }\\n} \\nResult: Command search returned: 103 ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I have found the number of gold medals China won in the 2023 Chengdu Universiade, which is 103. Now, I need to save this information for future reference. I will use the \\'write_file\\' command to do this.\",\\n        \"reasoning\": \"The \\'write_file\\' command is the most appropriate in this situation because it allows me to save important information to a file for future reference.\",\\n        \"plan\": \"- Use the \\'write_file\\' command to save the number of gold medals China won in the 2023 Chengdu Universiade to a file.\\\\n- Finish the task.\",\\n        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\\n        \"speak\": \"I am going to save the number of gold medals China won in the 2023 Chengdu Universiade to a file.\"\\n    },\\n    \"command\": {\\n        \"name\": \"write_file\",\\n        \"args\": {\\n            \"file_path\": \"2023_Chengdu_Universiade_China_Gold_Medal_Count.txt\",\\n            \"text\": \"China won 103 gold medals in the 2023 Chengdu Universiade.\",\\n            \"append\": false\\n        }\\n    }\\n} \\nResult: Command write_file returned: File written successfully to 2023_Chengdu_Universiade_China_Gold_Medal_Count.txt. ']\n",
            "\n",
            "\n",
            "Human: Determine which next command to use, and respond using the format specified above:\n",
            "AI: {\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I need to find out the number of gold medals China won in the 2023 Chengdu Universiade. To do this, I will use the 'search' command to look up this information online.\",\n",
            "        \"reasoning\": \"The 'search' command is the most appropriate in this situation because it allows me to find current and historical data from the internet.\",\n",
            "        \"plan\": \"- Use the 'search' command to find the number of gold medals China won in the 2023 Chengdu Universiade.\\n- Save the information to a file for future reference.\",\n",
            "        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\n",
            "        \"speak\": \"I am going to search for the number of gold medals China won in the 2023 Chengdu Universiade.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"search\",\n",
            "        \"args\": {\n",
            "            \"tool_input\": \"2023 Chengdu Universiade China gold medal count\"\n",
            "        }\n",
            "    }\n",
            "}\n",
            "System: Command search returned: 103\n",
            "Human: Determine which next command to use, and respond using the format specified above:\n",
            "AI: {\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I have found the number of gold medals China won in the 2023 Chengdu Universiade, which is 103. Now, I need to save this information for future reference. I will use the 'write_file' command to do this.\",\n",
            "        \"reasoning\": \"The 'write_file' command is the most appropriate in this situation because it allows me to save important information to a file for future reference.\",\n",
            "        \"plan\": \"- Use the 'write_file' command to save the number of gold medals China won in the 2023 Chengdu Universiade to a file.\\n- Finish the task.\",\n",
            "        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\n",
            "        \"speak\": \"I am going to save the number of gold medals China won in the 2023 Chengdu Universiade to a file.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"write_file\",\n",
            "        \"args\": {\n",
            "            \"file_path\": \"2023_Chengdu_Universiade_China_Gold_Medal_Count.txt\",\n",
            "            \"text\": \"China won 103 gold medals in the 2023 Chengdu Universiade.\",\n",
            "            \"append\": false\n",
            "        }\n",
            "    }\n",
            "}\n",
            "System: Command write_file returned: File written successfully to 2023_Chengdu_Universiade_China_Gold_Medal_Count.txt.\n",
            "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{\n",
            "    \"thoughts\": {\n",
            "        \"text\": \"I have successfully written the number of gold medals China won in the 2023 Chengdu Universiade to a file. Now, I need to signal that I have finished all my objectives.\",\n",
            "        \"reasoning\": \"The 'finish' command is the most appropriate in this situation because it allows me to signal that I have completed all my tasks.\",\n",
            "        \"plan\": \"- Use the 'finish' command to signal that I have completed all my tasks.\",\n",
            "        \"criticism\": \"None at this stage, the plan seems efficient and effective.\",\n",
            "        \"speak\": \"I have completed all my tasks.\"\n",
            "    },\n",
            "    \"command\": {\n",
            "        \"name\": \"finish\",\n",
            "        \"args\": {\n",
            "            \"response\": \"I have found and saved the number of gold medals China won in the 2023 Chengdu Universiade.\"\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I have found and saved the number of gold medals China won in the 2023 Chengdu Universiade.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.run([\"2023年成都大运会，中国金牌数是多少\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50dbf7ae-e7b7-494d-afc0-0607a8207188",
      "metadata": {
        "id": "50dbf7ae-e7b7-494d-afc0-0607a8207188"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7bcd78b-613c-4590-aa1a-7823be14c3d4",
      "metadata": {
        "id": "a7bcd78b-613c-4590-aa1a-7823be14c3d4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}